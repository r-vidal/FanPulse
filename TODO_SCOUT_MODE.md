# üìã FANPULSE - TODO TECHNIQUE SCOUT MODE (Ajout 2 Features)

## üè¢ TIER: LABEL (‚Ç¨999/mois) - SUITE SCOUT MODE

---

## FEATURE 18: Scout Mode - Auto-Filtering Quotidien par Style/Genre

### Frontend √† cr√©er

#### üìÑ Page "Scout Preferences" - Configuration filtres permanents

- [ ] Section genres prioritaires (checkboxes, max 3)
- [ ] Section sous-genres par genre principal
- [ ] Section zones g√©ographiques (checkboxes multi-select)
- [ ] Slider taille artiste (min/max monthly listeners)
- [ ] Section exclusions (labels concurrents, controverses)
- [ ] Section coh√©rence catalogue:
  - [ ] Toggle "Ne proposer que artistes similaires √† mon roster"
  - [ ] Slider threshold similarit√© (0-100%)
  - [ ] Multi-select artistes de r√©f√©rence
- [ ] Bouton "Sauvegarder pr√©f√©rences"
- [ ] Preview r√©sultats bas√©s sur filtres (combien d'artistes matchent)

#### üìä Dashboard Scout avec filtres actifs

- [ ] Banner r√©sum√© filtres actifs
- [ ] Compteur "X prospects aujourd'hui (sur Y scann√©s)"
- [ ] Liste top 20-50 prospects pr√©-filtr√©s
- [ ] Badge "Match catalogue" sur chaque prospect (pourcentage)
- [ ] Bouton "Modifier filtres" (vers page preferences)
- [ ] Bouton "Voir tous scans bruts" (847 artistes avant filtre)
- [ ] Stats filtrage: "6,500 exclus par genre, 2,000 par r√©gion, etc."

#### üé¥ Card Prospect avec info match

- [ ] Badge "78% match avec Luna" (artiste similaire)
- [ ] Section "Pourquoi ce prospect" avec raisons:
  - [ ] "M√™me genre: Afrobeat"
  - [ ] "Tempo similaire: 95 BPM"
  - [ ] "Fanbase 45% commune avec Alex"
- [ ] Graphique radar comparison (audio features vs artiste r√©f√©rence)

### Backend API

- [ ] **Endpoint POST `/api/scout/preferences`**
  - [ ] Body: `genres`, `sub_genres`, `regions`, `listener_range`, `exclusions`, `catalog_match_config`
  - [ ] Validation: max 3 genres, min/max listeners coh√©rents
  - [ ] Sauvegarde pr√©f√©rences user dans DB

- [ ] **Endpoint GET `/api/scout/preferences?user_id={user_id}`**
  - [ ] Response: pr√©f√©rences actives compl√®tes

- [ ] **Endpoint GET `/api/scout/daily-scan?user_id={user_id}`**
  - [ ] Response: top 20-50 prospects filtr√©s selon pr√©f√©rences
  - [ ] Inclut pour chaque: `breakout_score`, `catalog_match_score`, `match_reasons`

- [ ] **Endpoint GET `/api/scout/scan-stats?user_id={user_id}&date={date}`**
  - [ ] Response: stats d√©taill√©es scan quotidien
  - [ ] `total_scanned`, `matched_filters`, `filtered_out`, `filter_breakdown`

- [ ] **Endpoint GET `/api/scout/all-scans?user_id={user_id}&date={date}`**
  - [ ] Response: tous les 10k artistes scann√©s (avant filtre)
  - [ ] Pour power users qui veulent voir ce qu'ils ratent

- [ ] **Endpoint POST `/api/scout/preview-filters`**
  - [ ] Body: filtres temporaires (pour tester)
  - [ ] Response: combien d'artistes matcheraient (sans sauvegarder)

### Algorithmes

#### A) Genre Classification (ML Model)

- [ ] **Entra√Ænement mod√®le classification multi-label**
  - [ ] Dataset n√©cessaire:
    - [ ] 100,000+ tracks Spotify avec genres confirm√©s
    - [ ] Labelling manuel si n√©cessaire (20 genres principaux)
  - [ ] Architecture: Multi-label classifier (un artiste peut √™tre "rap + afrobeat")
  - [ ] Features input:
    - [ ] Audio features Spotify (11 dimensions):
      - `danceability`, `energy`, `key`, `loudness`, `mode`
      - `speechiness`, `acousticness`, `instrumentalness`
      - `liveness`, `valence`, `tempo`
    - [ ] Playlist context features:
      - Genres des playlists o√π artiste appara√Æt
      - Noms playlists (NLP: "Rap FR", "Drill UK", etc.)
    - [ ] Bio/metadata features:
      - Keywords bio artiste (scraping Spotify)
      - Genre tags Spotify (quand disponibles)
    - [ ] Collaboration network:
      - Genres des artistes avec qui il collabore
  - [ ] Output: `{primary_genre: "rap", sub_genres: ["drill", "trap"], confidence: 0.87}`

- [ ] **Algorithme classification en production**
  - [ ] Pour chaque artiste scann√©:
    - [ ] Fetch audio features Spotify API
    - [ ] Run mod√®le ML ‚Üí pr√©diction genre
    - [ ] Si confidence < 70% ‚Üí classification "unknown" (√† v√©rifier manuellement)
    - [ ] Store r√©sultats dans DB

#### B) Geographic Detection

- [ ] **Localisation artiste (multi-sources)**
  - [ ] Source 1: Spotify artist metadata
    - Field "country" dans API (quand dispo)
  - [ ] Source 2: Top cities fanbase
    - Si 70%+ fans dans 1 pays ‚Üí artiste probablement de ce pays
    - Pond√©ration: Paris 40% + Lyon 15% + Marseille 10% = France probable
  - [ ] Source 3: Langue lyrics
    - D√©tection langue via Genius API lyrics
    - Fran√ßais ‚Üí France probable (ou Belgique/Suisse/Qu√©bec)
  - [ ] Source 4: Bio scraping
    - Cherche "based in", "from", "Paris", "Lyon", etc.
  - [ ] Score de confiance g√©ographique (0-100%)

#### C) Catalog Match Score (Similarit√©)

- [ ] **Calcul similarit√© audio (0-100%)**
  - [ ] Pour chaque artiste prospect:
    - [ ] Compare avec artistes de r√©f√©rence du label
    - [ ] M√©thode: Cosine similarity sur audio features
    - [ ] Features vectoris√©es: `[danceability, energy, acousticness, ...]`
    - [ ] Formule: `similarity = cosine(vector_prospect, vector_reference)`
  - [ ] Si plusieurs artistes r√©f√©rence ‚Üí prend le max similarity

- [ ] **Calcul similarit√© genre**
  - [ ] Genre exact match = +30 pts
  - [ ] Sous-genre overlap = +20 pts
  - [ ] Genre adjacent (rap vs trap) = +10 pts

- [ ] **Calcul fanbase overlap (si data disponible)**
  - [ ] Via Spotify API (limit√©, pas toujours dispo)
  - [ ] Si >30% fans communs = +20 pts

- [ ] **Score final Catalog Match**
  - [ ] Audio similarity: 50%
  - [ ] Genre match: 30%
  - [ ] Fanbase overlap: 20%
  - [ ] Total: 0-100 score

- [ ] **G√©n√©ration raisons match**
  - "M√™me genre: Afrobeat"
  - "Tempo similaire: 95 BPM (vs 98 pour Luna)"
  - "Energy level comparable: 0.78 (vs 0.81 pour Alex)"
  - "Fanbase 45% commune avec Alex"

#### D) Filtrage Quotidien (Pipeline)

- [ ] **Processus de filtrage s√©quentiel**

  **√âtape 1: Scan baseline 10,000 artistes**
  - [ ] Crit√®res baseline (invariants):
    - Monthly listeners 10k-150k (√©vite trop petit/trop gros)
    - Compte Spotify v√©rifi√©
    - Minimum 3 tracks sortis
    - Actif derniers 90 jours

  **√âtape 2: Filtre genre**
  - [ ] Classifie genre chaque artiste (ML model)
  - [ ] Keep seulement si genre IN user preferences
  - [ ] Log: "6,500 artistes filtr√©s (genre non-match)"

  **√âtape 3: Filtre g√©ographique**
  - [ ] D√©tecte pays artiste
  - [ ] Keep seulement si pays IN user preferences
  - [ ] Log: "2,000 artistes filtr√©s (g√©o non-match)"

  **√âtape 4: Filtre exclusions**
  - [ ] Check si artiste d√©j√† sign√© (labels exclus)
  - [ ] Check controverses (si enabled)
  - [ ] Log: "150 artistes filtr√©s (exclusions)"

  **√âtape 5: Calcul Catalog Match (si enabled)**
  - [ ] Pour artistes restants, calcule similarity
  - [ ] Keep seulement si score > threshold (ex: 70%)
  - [ ] Log: "980 artistes filtr√©s (catalog match insuffisant)"

  **√âtape 6: Calcul Breakout Score**
  - [ ] Pour les ~200 artistes restants
  - [ ] Calcule score breakout complet

  **√âtape 7: Sort et s√©lection top 20-50**
  - [ ] Sort by Breakout Score DESC
  - [ ] Take top 20-50
  - [ ] Store r√©sultats pour user

- [ ] **Optimisation performance**
  - [ ] Filtres rapides d'abord (genre, g√©o) avant calculs lourds
  - [ ] Parall√©lisation calculs Catalog Match (multiprocessing)
  - [ ] Cache r√©sultats classification genre (30 jours)

### Database

#### Table `scout_preferences`

```sql
- id (uuid)
- user_id (uuid, FK)
- genres (jsonb) # ["rap", "afrobeat", "pop"]
- sub_genres (jsonb) # {"rap": ["drill", "trap"], "afrobeat": ["afrobeats", "afro-fusion"]}
- regions (jsonb) # ["france", "belgium", "switzerland"]
- listener_min (int) # 10000
- listener_max (int) # 150000
- exclusions (jsonb) # {
  #   signed_labels: ["universal", "sony"],
  #   controversies: true,
  #   already_contacted: true
  # }
- catalog_match_enabled (boolean)
- catalog_match_threshold (int) # 70 (score minimum)
- reference_artist_ids (jsonb) # [artist_id_1, artist_id_2, ...] pour similarit√©
- created_at (timestamp)
- updated_at (timestamp)
- PRIMARY KEY(id)
- UNIQUE(user_id)
```

#### Table `artist_classifications` (Cache)

```sql
- artist_id (varchar)
- primary_genre (varchar) # "rap"
- sub_genres (jsonb) # ["drill", "trap"]
- confidence (float) # 0.87
- audio_features (jsonb) # Spotify audio features vectoris√©es
- calculated_at (timestamp)
- expires_at (timestamp) # Cache 30 jours
- PRIMARY KEY(artist_id)
- INDEX(primary_genre)
```

#### Table `artist_locations` (Cache)

```sql
- artist_id (varchar)
- country (varchar) # "france"
- cities (jsonb) # ["paris", "lyon"]
- confidence (float) # 0.92
- sources (jsonb) # ["spotify_metadata", "fanbase_geo", "bio_scraping"]
- calculated_at (timestamp)
- expires_at (timestamp)
- PRIMARY KEY(artist_id)
```

#### Table `scout_daily_scan_logs`

```sql
- id (uuid)
- user_id (uuid, FK)
- scan_date (date)
- total_scanned (int) # 10000
- after_genre_filter (int) # 3500
- after_geo_filter (int) # 1500
- after_exclusions (int) # 1350
- after_catalog_match (int) # 370
- top_prospects_count (int) # 50
- top_prospect_ids (jsonb) # [artist_ids]
- filter_breakdown (jsonb) # Stats d√©taill√©es
- processing_time_seconds (int)
- created_at (timestamp)
- PRIMARY KEY(id)
- INDEX(user_id, scan_date)
```

#### Table `catalog_match_scores` (Cache)

```sql
- user_id (uuid, FK)
- prospect_artist_id (varchar)
- reference_artist_id (varchar) # L'artiste du roster le plus similaire
- match_score (int) # 0-100
- audio_similarity (float) # 0.78
- genre_similarity (float) # 0.90
- fanbase_overlap (float) # 0.45
- match_reasons (jsonb) # ["m√™me genre", "tempo similaire", ...]
- calculated_at (timestamp)
- expires_at (timestamp) # Recalcule tous les 7 jours
- PRIMARY KEY(user_id, prospect_artist_id)
- INDEX(match_score DESC)
```

### Background Jobs

- [ ] **Job `classify_artists_genres.py`** - Run continu (24/7)
  - [ ] Process queue d'artistes √† classifier
  - [ ] 1000 artistes/heure
  - [ ] Utilise ML model genre classification
  - [ ] Store r√©sultats dans `artist_classifications`
  - [ ] TTL cache: 30 jours

- [ ] **Job `detect_artist_locations.py`** - Run continu
  - [ ] Process queue d'artistes √† g√©olocaliser
  - [ ] Multi-sources aggregation
  - [ ] Store dans `artist_locations`
  - [ ] TTL cache: 30 jours

- [ ] **Job `daily_scout_scan_with_filters.py`** - Run 1am quotidien
  - [ ] Pour chaque user LABEL/ENTERPRISE avec Scout activ√©:
    - [ ] Load preferences
    - [ ] Execute pipeline filtrage (7 √©tapes)
    - [ ] Calculate Breakout Scores pour finalists
    - [ ] Select top 20-50
    - [ ] Store r√©sultats dans DB
    - [ ] Log stats dans `scout_daily_scan_logs`
  - [ ] Parall√©lisation par user
  - [ ] Total processing time: <30 minutes pour 100 users

- [ ] **Job `calculate_catalog_match_scores.py`** - Run 2am quotidien
  - [ ] Pour prospects filtr√©s de chaque user:
    - [ ] Calculate similarity avec artistes roster
    - [ ] Store best match + score
    - [ ] Generate match reasons
  - [ ] Cache r√©sultats 7 jours

- [ ] **Job `send_daily_scout_digest.py`** - Run 8am quotidien
  - [ ] Email r√©cap pour chaque user:
    - "Top 20 prospects aujourd'hui"
    - Highlights: 3 meilleurs prospects avec d√©tails
    - Stats: "847 scann√©s, 20 retenus"
    - CTA vers dashboard
  - [ ] Notification push mobile (si app)

### Int√©grations tierces

- [ ] **Spotify Web API**
  - [ ] Endpoint `/v1/audio-features/{id}` - Audio features track
  - [ ] Endpoint `/v1/artists/{id}` - Metadata artiste
  - [ ] Endpoint `/v1/artists/{id}/top-tracks` - Top tracks pour analyse
  - [ ] Rate limit: 100 req/sec (g√©rer avec queue)

- [ ] **Genius API** (optionnel)
  - [ ] Fetch lyrics pour language detection
  - [ ] Endpoint `/search` ‚Üí `/songs/{id}/lyrics`

### ML Models √† d√©velopper

#### Mod√®le 1: Genre Classification

- [ ] **Architecture**
  - [ ] Type: Multi-label Neural Network
  - [ ] Input: Vector 11 dimensions (audio features) + 50 dimensions (playlist embeddings)
  - [ ] Hidden layers: 128 ‚Üí 64 ‚Üí 32 neurons
  - [ ] Output: 20 genres (probabilit√©s multi-label)
  - [ ] Activation: Sigmoid (multi-label, pas softmax)

- [ ] **Dataset**
  - [ ] Source: Scrape Spotify playlists √©ditoriales
  - [ ] 100,000 tracks minimum
  - [ ] Labels: 20 genres principaux
  - [ ] Split: 80% train, 10% validation, 10% test

- [ ] **Training**
  - [ ] Loss: Binary crossentropy (multi-label)
  - [ ] Optimizer: Adam
  - [ ] Epochs: 50-100
  - [ ] Early stopping on validation loss
  - [ ] Target accuracy: >85%

- [ ] **Deployment**
  - [ ] Save model: .h5 ou .pkl
  - [ ] API inference: FastAPI endpoint
  - [ ] Latency target: <100ms per prediction
  - [ ] Batch processing: 100 artistes en parall√®le

---

## FEATURE 19: Scout Mode - AI Detection + Authenticity Score

### Frontend √† cr√©er

#### üéØ Section "AI Detection" sur profil prospect

- [ ] Badge visuel principal: "‚úÖ 92/100 HUMAN" ou "‚ö†Ô∏è 65/100 SUSPECT"
- [ ] Gauge Authenticity Score (0-100) avec code couleur:
  - [ ] 80-100: Vert (HUMAN verified)
  - [ ] 60-79: Orange (SUSPECT, moderate risk)
  - [ ] 0-59: Rouge (AI LIKELY, high risk)
- [ ] Probabilit√© musique IA: "8% (Faible)"
- [ ] Confiance d√©tection: "94%"

#### üìä Panel d√©taill√© "Signaux D√©tection"

- [ ] **Section "‚úÖ Signaux Positifs (Humain)":**
  - [ ] Liste bullet points:
    - "Pr√©sence social media active: 47 posts Instagram"
    - "Photos concerts/studio: 12 trouv√©es"
    - "Interviews vid√©o: 3 trouv√©es (YouTube)"
    - "Audio analysis: variations naturelles d√©tect√©es"
    - "Lyrics: style personnel coh√©rent sur 8 tracks"

- [ ] **Section "‚ö†Ô∏è Signaux N√©gatifs (IA)":**
  - [ ] Liste bullet points avec contexte:
    - "Sorties tr√®s r√©guli√®res: 1 track/semaine"
    - "  ‚Üí Peut √™tre productif, mais pattern IA possible"

- [ ] Bouton "Voir analyse compl√®te" (modal d√©tails)

#### üîç Modal "Analyse Compl√®te AI Detection"

- [ ] Onglets:
  - [ ] Audio Analysis (waveform + spectrogramme)
  - [ ] Social Media Audit (screenshots posts)
  - [ ] Web Presence (liens interviews/press)
  - [ ] Lyrics Analysis (coh√©rence style)
- [ ] Recommandation finale: "Safe to approach" ou "Investigate further"

#### ‚öôÔ∏è Filtres Scout par Authenticity

- [ ] Dans page Scout Preferences:
  - [ ] Checkbox "Seulement artistes humains v√©rifi√©s"
  - [ ] Slider "Authenticity Score minimum: [80]"
  - [ ] Checkbox "Inclure artistes suspects (60-79)" avec warning
  - [ ] Checkbox "Inclure tous (m√™me IA probable)" avec gros warning

#### üìã Liste prospects avec badges authenticity

- [ ] Dans dashboard Scout, chaque prospect a badge:
  - [ ] "‚úÖ 92/100 Human"
  - [ ] "‚ö†Ô∏è 65/100 Suspect" avec ic√¥ne warning
  - [ ] "üö® 45/100 AI Likely" avec ic√¥ne danger
- [ ] Click badge ‚Üí ouvre panel d√©tection
- [ ] Sort par authenticity score (optionnel)

#### üìà Dashboard Analytics AI Detection

- [ ] Stats globales:
  - [ ] "847 artistes scann√©s ce mois"
  - [ ] "782 humains v√©rifi√©s (92%)"
  - [ ] "53 suspects (6%)"
  - [ ] "12 IA probable (2%)"
- [ ] Graphique √©volution d√©tection IA dans le temps
- [ ] Top 10 signaux qui pr√©disent IA (data viz)

### Backend API

- [ ] **Endpoint GET `/api/scout/prospect/{artist_id}/ai-detection`**
  - [ ] Response compl√®te avec authenticity_score, ai_probability, confidence, status
  - [ ] Signals positive/negative avec weights
  - [ ] Breakdown par composante (audio, social, metadata, lyrics, web)
  - [ ] Recommendation et red_flags

- [ ] **Endpoint GET `/api/scout/ai-detection/batch`**
  - [ ] Body: `{ artist_ids: [id1, id2, ...] }` (max 100)
  - [ ] Response: Array de r√©sultats AI detection
  - [ ] Pour affichage bulk dans liste prospects

- [ ] **Endpoint POST `/api/scout/ai-detection/analyze`**
  - [ ] Body: `{ artist_id, force_refresh: false }`
  - [ ] D√©clenche analyse compl√®te imm√©diate
  - [ ] Pour r√©analyser si doute ou nouvelle data

- [ ] **Endpoint GET `/api/scout/ai-detection/stats?user_id={user_id}`**
  - [ ] Response: Stats agr√©g√©es d√©tection IA
  - [ ] Pour dashboard analytics

- [ ] **Endpoint PUT `/api/scout/preferences/ai-threshold`**
  - [ ] Body: `{ min_authenticity_score: 80, include_suspects: false }`
  - [ ] Update pr√©f√©rences filtrage AI

### Algorithmes AI Detection

#### A) Audio Analysis (ML Model - Le plus critique)

- [ ] **Mod√®le Deep Learning: AI Music Detection**
  - [ ] Architecture: Convolutional Neural Network (CNN)
  - [ ] Input: Spectrogramme mel-scale (128 bins √ó 1000 frames)
  - [ ] Convolution layers: 3-4 layers avec filters [32, 64, 128, 256]
  - [ ] Pooling: MaxPooling apr√®s chaque conv
  - [ ] Dense layers: 512 ‚Üí 256 ‚Üí 1 (sigmoid output)
  - [ ] Output: Probabilit√© IA (0-1)

- [ ] **Dataset n√©cessaire** (CRITIQUE)
  - [ ] **Tracks HUMAINES** (50,000 minimum):
    - Source 1: Scrape Spotify artistes v√©rifi√©s √©tablis
    - Source 2: Acheter dataset MusicNet, MAESTRO
    - Label: "human" = 0
  - [ ] **Tracks IA** (50,000 minimum):
    - G√©n√®re avec: Suno, Udio, MusicGen, Stable Audio
    - Tous genres, tous styles
    - Label: "ai" = 1
  - [ ] **Augmentation data**:
    - Time stretching, pitch shifting
    - Background noise addition
    - Pour robustesse mod√®le

- [ ] **Features audio d√©tect√©es (pourquoi IA)**
  - [ ] Spectral artifacts sp√©cifiques IA:
    - Patterns r√©guliers inhumains dans hautes fr√©quences
    - Absence de micro-variations temporelles
    - Over-compression dynamique
  - [ ] Vocal analysis:
    - Breath sounds absents/trop parfaits
    - Consonantes trop "propres"
    - Vibrato artificiel (trop r√©gulier)
  - [ ] Harmonic complexity:
    - IA souvent simpliste harmoniquement
    - Progressions chord trop pr√©visibles
  - [ ] Mixing artifacts:
    - IA = trop "clean", pas d'imperfections
    - Humans = micro-erreurs subtiles (phase issues, etc.)

- [ ] **Training process**
  - [ ] Loss: Binary crossentropy
  - [ ] Optimizer: Adam (lr=0.0001)
  - [ ] Batch size: 32
  - [ ] Epochs: 100 avec early stopping
  - [ ] Validation split: 20%
  - [ ] Target accuracy: >92%
  - [ ] **IMPORTANT**: Re-entra√Æner tous les 3 mois (IA √©volue)

- [ ] **Inference en production**
  - [ ] Pour chaque track artiste (3-5 tracks analys√©s):
    - Download preview 30s via Spotify API
    - Convert to mel-spectrogramme
    - Run CNN model ‚Üí probabilit√© IA
  - [ ] Agr√©gation: Moyenne probabilit√© sur 3-5 tracks
  - [ ] Si variance √©lev√©e (tracks inconsistants) ‚Üí red flag
  - [ ] Latency target: <5 secondes par track

#### B) Metadata & Release Pattern Analysis

- [ ] **Release Frequency Analyzer**
  - [ ] Fetch discographie compl√®te artiste (Spotify API)
  - [ ] Calcul release frequency:
    - Tracks/mois derniers 6 mois
    - R√©gularit√© (√©cart-type entre releases)
  - [ ] Patterns suspects:
    - >4 tracks/mois pendant 3+ mois = üö® Red flag (humain impossible)
    - Exactement 1 track/semaine pendant 12+ semaines = ‚ö†Ô∏è Warning (bot possible)
    - Release tous les X jours (pattern machine) = üö® Red flag
  - [ ] Pattern normal:
    - 1-3 tracks/mois irr√©gulier = ‚úÖ OK
    - Bursts puis pauses = ‚úÖ OK (campagne promo)

- [ ] **ISRC Pattern Detection**
  - [ ] Certains g√©n√©rateurs IA ont ISRC patterns:
    - Pr√©fixes sp√©cifiques (ex: "QZ" prefix)
    - S√©quences num√©riques suspectes
  - [ ] Database patterns connus:
    - Maintenir liste ISRC prefixes IA connus
    - Update avec community reports

- [ ] **Distributor Analysis**
  - [ ] Certains distributeurs sp√©cialis√©s IA:
    - Liste distributors suspects (Soundful, etc.)
    - Si artiste via distributeur IA-friendly = ‚ö†Ô∏è Warning
  - [ ] Cross-check avec d'autres signaux

- [ ] **Track Naming Patterns**
  - [ ] IA a souvent naming g√©n√©rique:
    - "Track 1", "Track 2", "Untitled", "Song 01"
    - Noms tr√®s g√©n√©riques ("Summer Vibes", "Night Drive")
  - [ ] Regex patterns pour d√©tecter
  - [ ] Score: Plus g√©n√©rique = plus suspect

#### C) Social Media Presence (Web Scraping)

- [ ] **Instagram Analysis**
  - [ ] Via Instagram Graph API:
    - Nombre total posts
    - Nombre posts derniers 90 jours (activit√© r√©cente)
    - Types posts: Photos vs Videos vs Reels
    - Captions analysis (NLP: personnel vs bot)
  - [ ] Scoring:
    - 0 posts = 0/100 (üö® √ânorme red flag)
    - 1-5 posts = 10/100 (‚ö†Ô∏è Tr√®s suspect)
    - 5-20 posts = 40/100 (‚ö†Ô∏è Suspect)
    - 20-50 posts = 70/100 (‚úÖ Probable humain)
    - 50+ posts actifs = 95/100 (‚úÖ Confirm√© humain)
  - [ ] **Detection photos r√©elles**
    - Photos studio: √©quipement visible = ‚úÖ Humain
    - Photos concerts: sc√®ne, public = ‚úÖ Humain
    - Selfies vari√©s = ‚úÖ Humain
    - Photos stock/AI-generated faces = üö® Red flag
      - Utiliser API d√©tection deepfake (Sensity, etc.)
  - [ ] **Engagement analysis**
    - Comments authentiques:
      - Scrape 50 derniers comments
      - NLP: Comments personnels vs bots
      - Presence amis/famille = ‚úÖ Humain
    - Like/follower ratio:
      - Ratio anormal (tous posts 10k likes mais 500 followers) = üö® Bot

- [ ] **TikTok Analysis**
  - [ ] Via TikTok API (ou scraping):
    - Nombre vid√©os
    - Face visible dans vid√©os = ‚úÖ Humain
    - Behind-the-scenes studio = ‚úÖ Humain
    - Lips-sync challenges = ‚úÖ Humain (AI ne peut pas)
  - [ ] Deepfake detection:
    - Si face visible, run deepfake detector
    - APIs: Sensity, Microsoft Video Authenticator

- [ ] **YouTube Analysis**
  - [ ] Via YouTube Data API:
    - Nombre vid√©os channel
    - Types: Interviews, live performances, studio sessions
    - Interview face visible = ‚úÖ‚úÖ Strong signal humain
    - Concerts film√©s = ‚úÖ‚úÖ Strong signal
  - [ ] Scoring:
    - 0 vid√©os = 0/100
    - 1-3 vid√©os lyrics only = 30/100
    - 3+ vid√©os avec face = 90/100
    - Interviews professionnelles = 100/100

#### D) Lyrics Analysis (NLP)

- [ ] **Personal Style Consistency**
  - [ ] Fetch lyrics 5-10 derni√®res tracks (Genius API)
  - [ ] Analyse:
    - [ ] Vocabulaire r√©current:
      - Argot sp√©cifique r√©gional ("wesh", "gros", etc.)
      - Expressions personnelles uniques
    - [ ] Th√®mes personnels:
      - Histoires v√©cues coh√©rentes (famille, enfance, ville)
      - R√©f√©rences locales (rues, quartiers)
    - [ ] Flow patterns:
      - Sch√©mas de rimes personnels
      - Cadences signature
  - [ ] Inconsistency detection:
    - Si track 1 parle "ma m√®re √† Paris" et track 5 "my mom in LA" = üö® Incoh√©rent
    - Si vocabulaire change radicalement = ‚ö†Ô∏è Suspect

- [ ] **AI Text Detection**
  - [ ] Utilise GPT-Zero API ou Originality.ai
  - [ ] Run sur lyrics de 3-5 tracks
  - [ ] Output: % probabilit√© g√©n√©r√© par GPT/IA
  - [ ] Si >70% = üö® Red flag

- [ ] **Generic vs Specific Content**
  - [ ] NLP scoring:
    - Mentions lieux sp√©cifiques = +10 pts (Paris, Brooklyn, etc.)
    - Noms personnes = +10 pts (m√™me si invent√©s, style personnel)
    - Dates/√©v√©nements = +10 pts
    - √âmotions nuanc√©es = +15 pts (pas juste "happy/sad")
  - [ ] IA tend √† √™tre g√©n√©rique:
    - "Love", "Party", "Night", "Dreams" sans d√©tails
    - Clich√©s sans profondeur

#### E) Web Presence & Press Coverage

- [ ] **Google Search Scraping**
  - [ ] Queries automatiques:
    - "{artist_name} interview"
    - "{artist_name} concert"
    - "{artist_name} live performance"
    - "{artist_name} behind the scenes"
    - "{artist_name} biography"
  - [ ] Parse r√©sultats (top 20):
    - Compter articles pertinents
    - Extraire dates publications
    - V√©rifier sources cr√©dibles (blogs musicaux, magazines)
  - [ ] Scoring:
    - 0 r√©sultats = 0/100 (üö® Red flag)
    - 1-5 r√©sultats = 40/100
    - 5-20 r√©sultats = 70/100
    - 20+ r√©sultats cr√©dibles = 95/100

- [ ] **Press Mentions Database**
  - [ ] Scrape p√©riodiquement:
    - Music blogs (Pitchfork, Stereogum, etc.)
    - Magazines FR (Les Inrocks, T√©l√©rama, etc.)
    - Plateformes interview (Genius, Complex)
  - [ ] Store mentions artistes
  - [ ] Check si artiste prospect a mentions = ‚úÖ Humain

- [ ] **Verified Accounts Cross-Check**
  - [ ] Check badges v√©rifi√©s:
    - Spotify verified = +20 pts
    - Instagram verified = +30 pts
    - YouTube verified = +20 pts
  - [ ] Attention: IA bots peuvent acheter verifications fake
  - [ ] Cross-check avec autres signaux

#### F) Scoring Final Authenticity (0-100)

- [ ] **Pond√©ration composantes**

```
Authenticity Score = Weighted average:

1. Audio AI Detection (40%) - Le plus critique
   - ai_probability_inverse = (100 - ai_probability)
   - Si ai_probability < 10% ‚Üí 90-100 pts
   - Si ai_probability 10-30% ‚Üí 60-90 pts
   - Si ai_probability 30-50% ‚Üí 30-60 pts
   - Si ai_probability > 50% ‚Üí 0-30 pts

2. Social Media Presence (30%)
   - Instagram score (15%)
   - TikTok score (10%)
   - YouTube score (5%)

3. Metadata & Release Pattern (15%)
   - Release frequency normal = 100 pts
   - Patterns suspects = 0-50 pts

4. Lyrics Style Consistency (10%)
   - Personal style fort = 100 pts
   - G√©n√©rique = 50 pts
   - D√©tect√© IA = 0 pts

5. Web Presence & Press (5%)
   - Interviews trouv√©es = 100 pts
   - Rien trouv√© = 0 pts

TOTAL = Sum(component √ó weight)
```

- [ ] **Classification finale**
  - [ ] 80-100: ‚úÖ **HUMAN** (High confidence, safe to approach)
  - [ ] 60-79: ‚ö†Ô∏è **SUSPECT** (Moderate risk, investigate further)
  - [ ] 0-59: üö® **AI LIKELY** (High risk, avoid or request proof of humanity)

- [ ] **Confidence Score (0-100)**
  - [ ] Bas√© sur:
    - Nombre de signaux disponibles (plus = mieux)
    - Consistance entre signaux (si tous align√©s = high confidence)
    - Qualit√© data (Spotify API vs scraping = diff√©rent)
  - [ ] Formule:
```
confidence = (
  signal_count / max_signals * 0.5 +
  signal_consistency * 0.3 +
  data_quality_avg * 0.2
) * 100
```

### Database

#### Table `ai_detection_scores`

```sql
- id (uuid)
- artist_id (varchar)
- authenticity_score (int) # 0-100
- ai_probability (int) # 0-100 (probabilit√© musique IA)
- confidence (int) # 0-100
- status (enum: human, suspect, ai_likely)
- signals_positive (jsonb) # Array de signaux positifs d√©taill√©s
- signals_negative (jsonb) # Array de signaux n√©gatifs
- breakdown (jsonb) # {
  #   audio_score: 95,
  #   social_presence_score: 85,
  #   metadata_score: 90,
  #   lyrics_score: 88,
  #   web_presence_score: 92
  # }
- audio_analysis (jsonb) # R√©sultats d√©taill√©s audio ML
- social_media_data (jsonb) # Stats IG/TikTok/YouTube
- metadata_flags (jsonb) # Release pattern, ISRC, etc.
- lyrics_analysis (jsonb) # NLP results
- web_presence_data (jsonb) # Google search, press mentions
- recommendation (text) # "Safe to approach" ou "Investigate further"
- red_flags (jsonb) # Array de red flags critiques
- calculated_at (timestamp)
- expires_at (timestamp) # Recalcule tous les 30 jours
- PRIMARY KEY(id)
- UNIQUE(artist_id)
- INDEX(authenticity_score DESC)
- INDEX(status)
```

#### Table `ai_detection_cache_audio` (Performance)

```sql
- track_id (varchar)
- ai_probability (float) # 0-1
- spectral_artifacts_detected (boolean)
- breath_sounds_present (boolean)
- harmonic_complexity_score (float)
- mixing_imperfections_score (float)
- analyzed_at (timestamp)
- expires_at (timestamp) # Cache 90 jours
- PRIMARY KEY(track_id)
```

#### Table `known_ai_patterns` (Community DB)

```sql
- id (uuid)
- pattern_type (enum: isrc_prefix, distributor, naming_pattern)
- pattern_value (varchar) # "QZ-ABC", "SoundfulMusic", etc.
- confidence (float) # 0-1
- reported_count (int) # Nombre de reports community
- verified (boolean) # V√©rifi√© par admin
- created_at (timestamp)
- PRIMARY KEY(id)
```

### Background Jobs

- [ ] **Job `analyze_ai_detection_audio.py`** - Run continu (queue-based)
  - [ ] Process queue artistes √† analyser
  - [ ] Pour chaque artiste:
    - Download 3-5 tracks preview (30s) via Spotify API
    - Convert to mel-spectrogramme
    - Run CNN AI detection model
    - Agr√®ge r√©sultats (moyenne + variance)
    - Store dans `ai_detection_cache_audio`
  - [ ] Throughput: 200 artistes/heure
  - [ ] Priorit√©: nouveaux prospects > r√©analyses

- [ ] **Job `scrape_social_media_presence.py`** - Run continu
  - [ ] Process queue artistes
  - [ ] Pour chaque:
    - Instagram Graph API ‚Üí stats + posts r√©cents
    - TikTok API/scraping ‚Üí vid√©os count
    - YouTube Data API ‚Üí channel stats
  - [ ] Store r√©sultats structur√©s
  - [ ] Rate limiting respect√© (Instagram: 200 calls/hour)
  - [ ] Retry avec backoff si rate limited

- [ ] **Job `analyze_lyrics_consistency.py`** - Run continu
  - [ ] Process queue artistes
  - [ ] Fetch lyrics via Genius API (3-5 tracks)
  - [ ] NLP analysis:
    - Vocabulaire extraction
    - Th√®mes detection
    - GPT-Zero API pour AI detection
  - [ ] Store r√©sultats

- [ ] **Job `scrape_web_presence.py`** - Run continu
  - [ ] Google Custom Search API:
    - "{artist_name} interview"
    - "{artist_name} concert"
    - Parse top 20 r√©sultats
  - [ ] Store count + links
  - [ ] Update `ai_detection_scores`

- [ ] **Job `calculate_final_authenticity.py`** - Run apr√®s tous analyses
  - [ ] Agr√®ge r√©sultats 5 composantes
  - [ ] Calcule weighted score 0-100
  - [ ] Classification human/suspect/ai_likely
  - [ ] G√©n√®re recommandation
  - [ ] Store final score

- [ ] **Job `daily_ai_detection_batch.py`** - Run 3am quotidien
  - [ ] Pour tous nouveaux prospects scann√©s hier:
    - Trigger analyse compl√®te (pipeline 5 jobs)
    - Priorise prospects avec high Breakout Score
  - [ ] Pour prospects existants:
    - Re-scan si score expir√© (30 jours)

- [ ] **Job `update_ai_detection_models.py`** - Run weekly (dimanche)
  - [ ] Re-entra√Æne CNN audio detection avec nouvelles data
  - [ ] Collecte nouveaux samples IA (Suno, Udio releases)
  - [ ] Am√©liore pr√©cision continue
  - [ ] Deploy nouveau model si accuracy > ancien

- [ ] **Job `community_reports_aggregation.py`** - Run daily
  - [ ] Agr√®ge reports users (si feature community)
  - [ ] Update `known_ai_patterns` database
  - [ ] Flag artistes report√©s multiple fois

### Int√©grations tierces

- [ ] **Spotify Web API**
  - [ ] `/v1/tracks/{id}` - Metadata track
  - [ ] `/v1/tracks/{id}/audio-features` - Audio features
  - [ ] `/v1/artists/{id}/albums` - Discographie
  - [ ] Track preview URL (30s MP3) pour analyse

- [ ] **Instagram Graph API**
  - [ ] `/me/media` - Liste posts
  - [ ] `/media/{id}` - D√©tails post (likes, comments)
  - [ ] Rate limit: 200 calls/hour/token

- [ ] **TikTok API** (ou scraping si API indispo)
  - [ ] User profile info
  - [ ] Video count
  - [ ] Engagement metrics

- [ ] **YouTube Data API**
  - [ ] `channels.list` - Channel stats
  - [ ] `search.list` - Cherche interviews artiste
  - [ ] `videos.list` - D√©tails vid√©os

- [ ] **Genius API**
  - [ ] `/search` - Cherche artiste
  - [ ] `/songs/{id}/lyrics` - Fetch lyrics (si dispo)
  - [ ] Alternative: Scraping si API insuffisante

- [ ] **GPT-Zero API** ou **Originality.ai**
  - [ ] D√©tection texte g√©n√©r√© par IA
  - [ ] Input: lyrics text
  - [ ] Output: probability AI-generated

- [ ] **Sensity API** ou **Microsoft Video Authenticator**
  - [ ] Deepfake detection vid√©os
  - [ ] Input: video URL (TikTok, YouTube)
  - [ ] Output: deepfake probability

- [ ] **Google Custom Search API**
  - [ ] Programmable search engine
  - [ ] 100 queries/day gratuit, puis payant
  - [ ] Search "{artist_name} interview" etc.

### ML Models √† d√©velopper/int√©grer

#### Mod√®le 1: AI Music Detection CNN (PRIORITAIRE)

- [ ] **Architecture d√©taill√©e**

```
Input: Mel-spectrogram (128 √ó 1000 √ó 1)
‚Üì
Conv2D(32 filters, 3√ó3) + ReLU + BatchNorm
‚Üì
MaxPooling2D(2√ó2)
‚Üì
Conv2D(64 filters, 3√ó3) + ReLU + BatchNorm
‚Üì
MaxPooling2D(2√ó2)
‚Üì
Conv2D(128 filters, 3√ó3) + ReLU + BatchNorm
‚Üì
MaxPooling2D(2√ó2)
‚Üì
Conv2D(256 filters, 3√ó3) + ReLU + BatchNorm
‚Üì
GlobalAveragePooling2D
‚Üì
Dense(512) + ReLU + Dropout(0.5)
‚Üì
Dense(256) + ReLU + Dropout(0.3)
‚Üì
Dense(1) + Sigmoid
‚Üì
Output: AI probability (0-1)
```

- [ ] **Dataset collection strategy**
  - [ ] Phase 1: Initial 10k samples
    - 5k humains (Spotify top tracks artistes v√©rifi√©s)
    - 5k IA (g√©n√©rer avec Suno/Udio, 20 genres vari√©s)
    - Train baseline model
  - [ ] Phase 2: Scale to 50k
    - Acheter datasets: MusicNet, MAESTRO, FMA
    - G√©n√©rer plus IA samples (variations qualit√©/genres)
    - Augmentation: pitch shift, time stretch, noise
  - [ ] Phase 3: Continuous learning
    - Collecter samples via community reports
    - Re-train monthly avec nouvelles IA releases

- [ ] **Training infrastructure**
  - [ ] GPU n√©cessaire: NVIDIA A100 ou V100
  - [ ] Cloud option: AWS p3.2xlarge ou Google Cloud TPU
  - [ ] Training time estim√©: 48-72h pour 50k samples
  - [ ] Storage: 500GB pour spectrogrammes

- [ ] **Evaluation metrics**
  - [ ] Target: >92% accuracy
  - [ ] Precision: >90% (√©viter false positives)
  - [ ] Recall: >88% (d√©tecter le maximum d'IA)
  - [ ] F1-score: >90%
  - [ ] Confusion matrix analysis

- [ ] **Deployment**
  - [ ] Model serving: TensorFlow Serving ou TorchServe
  - [ ] API wrapper: FastAPI
  - [ ] Latency: <5s per track
  - [ ] Batch inference: 100 tracks en parall√®le
  - [ ] Fallback: Si model fail ‚Üí score neutre (50/100)

#### Mod√®le 2: Deepfake Video Detection (Optionnel, utiliser API)

- [ ] Int√©grer API existante plut√¥t que d√©velopper
- [ ] Sensity API ou Microsoft Video Authenticator
- [ ] Backup: FaceForensics++ model (open-source)

#### Mod√®le 3: AI Text Detection (Utiliser API)

- [ ] GPT-Zero API (recommand√©)
- [ ] Alternative: OpenAI Text Classifier
- [ ] Backup: Originality.ai

---

## üéØ PRIORIT√âS D√âVELOPPEMENT SCOUT MODE COMPLET

### Sprint 10-12 (MVP Scout - 3 semaines)
- ‚úÖ Scan automatique 10k artistes/jour
- ‚úÖ Breakout Prediction Score basique
- ‚úÖ Top 50 prospects/semaine
- ‚úÖ Dashboard Scout basique

### Sprint 13-14 (Auto-Filtering - 2 semaines)
- [ ] Genre Classification ML model (entra√Ænement)
- [ ] Page Scout Preferences (filtres config)
- [ ] Pipeline filtrage quotidien (7 √©tapes)
- [ ] Catalog Match Score algorithm
- [ ] Dashboard avec filtres actifs

### Sprint 15-18 (AI Detection - 4 semaines)
- [ ] Dataset collection (50k samples humains + IA)
- [ ] AI Music Detection CNN (training)
- [ ] Social media scraping (IG/TikTok/YouTube)
- [ ] Lyrics NLP analysis
- [ ] Web presence scraping
- [ ] Authenticity Score calculation
- [ ] UI badges + panels d√©tection
- [ ] Filtres authenticity dans preferences

---

## üìä M√âTRIQUES DE SUCC√àS

### Auto-Filtering:
- [ ] R√©duction bruit: 10,000 ‚Üí 20-50 prospects (99.5% filtrage)
- [ ] Pr√©cision filtres: >95% (prospects pertinents)
- [ ] Temps saved A&R: 10h ‚Üí 1h/semaine (90% √©conomie)

### AI Detection:
- [ ] Accuracy audio model: >92%
- [ ] False positive rate: <8% (important pour cr√©dibilit√©)
- [ ] Latency: <10s analyse compl√®te par artiste
- [ ] Coverage: 100% prospects scann√©s ont score authenticity

---

## üöÄ IMPACT BUSINESS

### Diff√©renciation march√©:
- üî• **PERSONNE** ne fait l'auto-filtering aussi pouss√©
- üî• **PERSONNE** ne fait la d√©tection IA musicale
- Ces 2 features = **√âNORMES** diff√©renciateurs 2025-2026

### Pricing justification:
- Scout Mode basique = ‚Ç¨999/mois (LABEL)
- Scout Mode + AI Detection = ‚Ç¨5,000/mois (ENTERPRISE)
- ROI: √âvite 1 seul mauvais signing (‚Ç¨50k perdu) = 50 mois d'abonnement

### Viral potential:
- "First platform to detect AI music automatically"
- Press coverage garantie (TechCrunch, Music Business Worldwide)
- Parlera de toi dans l'industrie
